# RNN(Recurrent Neural Network)

> 시계열에 많이 사용하고 자연어 처리에서도 많이 쓰임
>
> 출력이 자기 자신에게로 감, 되먹임
>
> 이전 데이터와 이후 데이터가 나와 관련이 있을 때 사용

![image-20200210163812345](C:\Users\student\AppData\Roaming\Typora\typora-user-images\image-20200210163812345.png)

- 신경 망의 기본구조와 크게 바뀌지 않는다.
- 가중치는 하나만 사용한다.
- RNN에서는 하이퍼블릭 탄젠트를 사용
- Y는 따로 주어지지 않는다.
- 문장이 길어지면 학습이 잘 안됨.
- relu를 쓰지 않으면 미분값이 작아지는 현상이 발생

![image-20200210165856721](C:\Users\student\AppData\Roaming\Typora\typora-user-images\image-20200210165856721.png)

> 용도에 따라 다양하게 적용



## LSTM(Long Short term Memory)

RNN 보완







feed forward

